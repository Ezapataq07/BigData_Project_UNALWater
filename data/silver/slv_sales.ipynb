{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10840348-070e-44d6-b532-fe221467465d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook to cleansed bronze.sales into silver.sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39c8a82d-de2e-41b1-bb5e-f605bf4acead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8834b695-e7b2-419a-957d-43499d5ea64b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,current_timestamp, expr\n",
    "from pyspark.sql.functions import (\n",
    "    col, to_timestamp, date_format, dayofmonth, hour,\n",
    "    minute, month, second, year\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c7ab0bd-2ba9-4f97-bbd7-1b37ff8cbc76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../config/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb7a622-8395-4c65-b922-df545e4dc824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ORIGIN_TABLE=\"brz_sales\"\n",
    "TARGET_TABLE=\"slv_sales\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7e9b79-e0a7-4f5b-879d-72c1eaeaf2b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Load data from brone.sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41b2e722-a344-41f3-ae36-854244d2c8db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_df = spark.readStream.format('delta').option(\"maxFilesPerTrigger\", 1).table(f\"{catalog_name}.{bronze_schema_name}.{ORIGIN_TABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17142ad7-b0ca-4845-a6cf-4c1af22515c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ee49468-50f7-4d0f-8758-200b239fe61a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "rename date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eda1b3d-ab45-4b6d-a0d7-d93dde3c515c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_df = bronze_df.withColumnRenamed(\"date\", \"event_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9fae019-1f3b-4633-976b-71c733c0a867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Date/Time enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecfcb907-c82b-48d2-aeac-70c590b5b548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_df = bronze_df.withColumn(\"event_date\", to_timestamp(col(\"event_date\"), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "\n",
    "bronze_df = bronze_df.withColumn(\"partition_date\", date_format(col(\"event_date\"), \"ddMMyyyy\")) \\\n",
    "       .withColumn(\"event_day\", dayofmonth(col(\"event_date\"))) \\\n",
    "       .withColumn(\"event_hour\", hour(col(\"event_date\"))) \\\n",
    "       .withColumn(\"event_minute\", minute(col(\"event_date\"))) \\\n",
    "       .withColumn(\"event_month\", month(col(\"event_date\"))) \\\n",
    "       .withColumn(\"event_second\", second(col(\"event_date\"))) \\\n",
    "       .withColumn(\"event_year\", year(col(\"event_date\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4de44d2f-649b-4202-9799-0d9916c458e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Location enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a18d2c3-fea2-4cf6-aa30-3fa73ce44a7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "neighborhoods_df = spark.read.table(f\"{silver_schema_name}.slv_neighborhoods\")\n",
    "neighborhoods_df = neighborhoods_df.select([\n",
    "    \"name\",\n",
    "    \"identification\",\n",
    "    \"geojson\"\n",
    "])\n",
    "neighborhoods_df = neighborhoods_df.withColumnRenamed(\"name\", \"district\").withColumnRenamed(\"identification\", \"neighborhood\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7625aaef-fb17-4c44-9997-19525bc50d06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Perform cross join between sales and neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755072ff-766d-4578-a0e0-83ca7b06dfd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "complete_df=bronze_df.crossJoin(neighborhoods_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8579be4f-fc93-4910-a801-5a3364317355",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define a function to validate if a given point is inside a Polygon/Multipolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ebd0a88-7f18-4f13-91d7-6a9e3ed2696a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql.types import BooleanType\n",
    "from shapely.geometry import Point, shape\n",
    "import json\n",
    "\n",
    "# UDF logic: receives lat/lon and geojsons per row\n",
    "@udf(BooleanType())\n",
    "def point_in_polygon(lat, lon, geojson):\n",
    "    try:\n",
    "        point = Point(lon, lat)\n",
    "        polygon_neighborhoods = shape(json.loads(geojson)) if geojson else None\n",
    "        in_neighborhoods = polygon_neighborhoods.contains(point) if polygon_neighborhoods else False\n",
    "        return in_neighborhoods\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Register the UDF\n",
    "# point_in_polygon_udf = udf(point_in_polygon, BooleanType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b41a394e-65fa-4034-ae7e-8cf72083c8c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Apply function and return the district and neighboorhood for each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "329e02d1-56c2-4b82-bc17-b0cb138131e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "complete_df=complete_df.withColumn(\"match_location\",point_in_polygon(col(\"latitude\"),col(\"longitude\"),col(\"geojson\")))\n",
    "complete_df=complete_df.filter(col(\"match_location\") == True).drop('geojson','match_location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebddebb3-2b6c-4ba3-911d-5e6052d0c6b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Validate against original bronze_df to find the record which location is unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1ec40b4-3d60-46c5-a72f-89dcdaabf036",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Write Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0b42dd7-0187-477a-8267-f60cc9d40cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(complete_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", silver_checkpoint_path)\n",
    "    .trigger(availableNow=True)\n",
    "    .table(f\"{catalog_name}.{silver_schema_name}.{TARGET_TABLE}\")\n",
    "    .awaitTermination()\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "shapely==2.1.1"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7643627261828097,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "slv_sales",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
